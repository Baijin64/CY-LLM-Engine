# CY-LLM Engine

> ğŸš€ **é«˜æ€§èƒ½** Â· **ä½¿ç”¨ç®€æ´** Â· **é«˜åº¦è‡ªå®šä¹‰** çš„å®Œæ•´ AI æœåŠ¡ç³»ç»Ÿ

ä¸€ä¸ªæ”¯æŒå¤šç§æ¨ç†å¼•æ“ï¼ˆvLLM / TensorRT-LLM / MindIEï¼‰å’Œå¤šç§ç¡¬ä»¶å¹³å°ï¼ˆNVIDIA GPU / åä¸º Ascend NPUï¼‰çš„ç»Ÿä¸€ AI æ¨ç†åç«¯ã€‚

---

## ğŸ“š æ–‡æ¡£å¯¼èˆª

> **ğŸ”— å®Œæ•´æ–‡æ¡£åœ¨çº¿é˜…è¯»**: [https://zread.ai/Baijin64/CY-LLM-Engine](https://zread.ai/Baijin64/CY-LLM-Engine)

### æ ¸å¿ƒæ–‡æ¡£

| æ–‡æ¡£ | æè¿° |
|------|------|
| [docs/README.md](./docs/README.md) | é¡¹ç›®è¯¦ç»†ä»‹ç»ä¸å¿«é€Ÿå…¥é—¨ |
| [docs/INSTALL.md](./docs/INSTALL.md) | è¯¦ç»†å®‰è£…ä¸é…ç½®æŒ‡å— |
| [docs/ARCHITECTURE.md](./docs/ARCHITECTURE.md) | æ¶æ„è®¾è®¡ä¸æ•°æ®æµè¯¦è§£ |
| [docs/API.md](./docs/API.md) | REST API ä¸ gRPC æ¥å£æ–‡æ¡£ |
| [docs/CONTRIBUTING.md](./docs/CONTRIBUTING.md) | è´¡çŒ®è€…è§„èŒƒä¸å¼€å‘æŒ‡å— |
| [docs/TESTING.md](./docs/TESTING.md) | æµ‹è¯•æŒ‡å—ä¸ CI é…ç½® |
| [docs/FAQ.md](./docs/FAQ.md) | å¸¸è§é—®é¢˜è§£ç­” |
| [docs/TRT_GUIDE.md](./docs/TRT_GUIDE.md) | TensorRT-LLM ä¸“ç”¨æŒ‡å— |

### å¿«é€ŸæŒ‡å—

| æ–‡ä»¶ | æè¿° |
|------|------|
| [QUICK_START.md](./QUICK_START.md) | å¿«é€Ÿå¼€å§‹æŒ‡å— (VRAM ä¼˜åŒ–ã€TRT è½¬æ¢) |

### é¡¹ç›®å†å²

| æ–‡ä»¶ | æè¿° |
|------|------|
| [docs/HISTORY/MIGRATION_SUMMARY.md](./docs/HISTORY/MIGRATION_SUMMARY.md) | EW_AI_Backend â†’ CY_LLM_Backend è¿ç§»æ€»ç»“ |
| [docs/HISTORY/PHASE2_3_UPGRADE_REPORT.md](./docs/HISTORY/PHASE2_3_UPGRADE_REPORT.md) | Phase 2 & 3 ä¼˜åŒ–å‡çº§æŠ¥å‘Š |

---

## âœ¨ æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | æè¿° |
|------|------|
| **å¤šå¼•æ“æ”¯æŒ** | vLLM (CUDA/Ascend)ã€TensorRT-LLMã€MindIE |
| **å¤šç¡¬ä»¶å¹³å°** | NVIDIA GPUã€åä¸º Ascend NPU |
| **ç»Ÿä¸€ CLI** | `./cy` / `./cy-llm` ä¸€é”®éƒ¨ç½²å’Œç®¡ç† |
| **æµå¼æ¨ç†** | SSE å®æ—¶æµå¼è¾“å‡º |
| **ä¼ä¸šçº§ç½‘å…³** | Kotlin + Spring WebFlux å“åº”å¼æ¶æ„ |
| **å¼¹æ€§ä¼¸ç¼©** | æ”¯æŒå¤š Worker å®ä¾‹è´Ÿè½½å‡è¡¡ |
| **å®Œæ•´è®­ç»ƒ** | LoRA/PEFT å¾®è°ƒæ”¯æŒ |
| **æ˜¾å­˜ä¼˜åŒ–** | VRAM é¢„ä¼°ä¸ OOM è‡ªåŠ¨é‡è¯• |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šCLI ä¸€é”®å¯åŠ¨ (æ¨è)

```bash
# 1. åˆå§‹åŒ–ç¯å¢ƒ
./cy-llm setup --engine cuda-vllm

# 2. å¯åŠ¨æœåŠ¡
./cy-llm start --model qwen2.5-7b

# 3. éªŒè¯éƒ¨ç½²
curl http://localhost:8080/api/v1/health
```

### æ–¹å¼äºŒï¼šDocker éƒ¨ç½² (æ¨èç”Ÿäº§)

```bash
# é…ç½®ç¯å¢ƒå˜é‡
cd CY_LLM_Backend/deploy
cp .env.example .env
vim .env

# å¯åŠ¨æœåŠ¡
docker compose up -d
```

### æ–¹å¼ä¸‰ï¼šæ‰‹åŠ¨å¯åŠ¨

```bash
# 1. å¯åŠ¨ Redis
docker run -d --name redis -p 6379:6379 redis:7-alpine

# 2. å¯åŠ¨ Coordinator (Java 21)
cd CY_LLM_Backend/coordinator
./gradlew bootRun

# 3. å¯åŠ¨ Worker (Python)
cd CY_LLM_Backend/worker
source .venv/bin/activate
python -m worker.main --serve --port 50051

# 4. å¯åŠ¨ Gateway (Java 21)
cd CY_LLM_Backend/gateway
./gradlew bootRun
```

æœåŠ¡å°†åœ¨ `http://localhost:8080` å¯åŠ¨ã€‚

---

## ğŸ¯ å¼•æ“é€‰æ‹©æŒ‡å—

| å¼•æ“ | ç¡¬ä»¶ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| `cuda-vllm` | NVIDIA GPU | PagedAttention, é«˜åå | é€šç”¨æ¨è |
| `cuda-trt` | NVIDIA GPU | æè‡´æ€§èƒ½, éœ€é¢„ç¼–è¯‘ | å›ºå®šæ¨¡å‹ç”Ÿäº§ |
| `ascend-vllm` | åä¸º NPU | å…¼å®¹ vLLM API | Ascend ç¯å¢ƒ |
| `ascend-mindie` | åä¸º NPU | å®˜æ–¹ä¼˜åŒ– | Ascend é«˜æ€§èƒ½ |

```bash
# ä½¿ç”¨ vLLM (é»˜è®¤)
./cy-llm start --engine cuda-vllm

# ä½¿ç”¨ TensorRT-LLM
./cy-llm start --engine cuda-trt

# ä½¿ç”¨åä¸º Ascend vLLM
./cy-llm start --engine ascend-vllm

# ä½¿ç”¨åä¸º Ascend MindIE
./cy-llm start --engine ascend-mindie
```

---

## ğŸ“– CLI å‘½ä»¤å‚è€ƒ

```bash
./cy-llm <command> [options]

Commands:
  setup       åˆå§‹åŒ–ç¯å¢ƒ (Conda + ä¾èµ– + Gateway)
  start       å¯åŠ¨å®Œæ•´æœåŠ¡ (Gateway + Worker)
  worker      ä»…å¯åŠ¨ Worker
  stop        åœæ­¢æ‰€æœ‰æœåŠ¡
  status      æŸ¥çœ‹æœåŠ¡çŠ¶æ€
  docker      Docker Compose éƒ¨ç½²
  test        è¿è¡Œæµ‹è¯•
  models      æ¨¡å‹ç®¡ç†
  convert-trt è½¬æ¢æ¨¡å‹ä¸º TensorRT-LLM å¼•æ“
  help        æ˜¾ç¤ºå¸®åŠ©

Options:
  --engine TYPE     æ¨ç†å¼•æ“ (cuda-vllm/cuda-trt/ascend-vllm/ascend-mindie)
  --model ID        æ¨¡å‹ ID
  --port PORT       Gateway ç«¯å£ (é»˜è®¤: 8080)
  -d, --daemon      åå°è¿è¡Œ

Examples:
  ./cy-llm setup --engine cuda-vllm       # åˆå§‹åŒ–
  ./cy start --model qwen2.5-72b          # å¯åŠ¨æŒ‡å®šæ¨¡å‹
  ./cy-llm start -d                       # åå°å¯åŠ¨
  ./cy-llm docker up --scale 2            # Docker åŒ Worker
  ./cy-llm status                         # æŸ¥çœ‹çŠ¶æ€
  ./cy-llm convert-trt --model Qwen/Qwen2.5-7B --output /models/trt  # è½¬æ¢ TRT æ¨¡å‹
```

---

## ğŸ›  æ¨ç†æ¥å£ç¤ºä¾‹

### æµå¼æ¨ç† (SSE)

```bash
curl -N -X POST http://localhost:8080/api/v1/inference/stream \
  -H "Content-Type: application/json" \
  -d '{"modelId": "qwen2.5-7b", "prompt": "è¯·æè¿°ä¸€ä¸‹æœªæ¥ AI çš„æ ·å­"}'
```

### éæµå¼æ¨ç†

```bash
curl -X POST http://localhost:8080/api/v1/inference \
  -H "Content-Type: application/json" \
  -d '{"modelId": "qwen2.5-7b", "prompt": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"}'
```

### è®­ç»ƒæ¥å£

```bash
curl -X POST http://localhost:8080/api/v1/training/start \
  -H "Content-Type: application/json" \
  -d '{
    "baseModel": "deepseek-ai/deepseek-llm-7b-chat",
    "outputDir": "/checkpoints/my_lora",
    "datasetPath": "/data/train.json"
  }'
```

---

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œé›†æˆæµ‹è¯•
./cy-llm test integration

# è¿è¡Œå•å…ƒæµ‹è¯•
./cy-llm test unit

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
./cy-llm test all
```

---

## ğŸ— ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Client                                   â”‚
â”‚                  (Browser / API Client)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP / SSE / WebSocket
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gateway (Kotlin)                              â”‚
â”‚              Spring WebFlux + gRPC Client                        â”‚
â”‚  ç«¯å£: 8080                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ gRPC (:50050)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Coordinator (Kotlin)                           â”‚
â”‚              Spring Boot + Redis + gRPC Server                   â”‚
â”‚  ç«¯å£: 50050                                                     â”‚
â”‚  â€¢ TaskQueueService (Redis ZSET ä¼˜å…ˆçº§é˜Ÿåˆ—)                     â”‚
â”‚  â€¢ PromptCacheService (Redis TTL ç¼“å­˜)                          â”‚
â”‚  â€¢ WorkerPoolManager (å¥åº·æ£€æŸ¥ + è´Ÿè½½å‡è¡¡)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ gRPC (:50051)
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Worker (Python)    â”‚     â”‚      Worker (Python)    â”‚
â”‚      NVIDIA GPU         â”‚     â”‚      Ascend NPU         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ InferenceEngine   â”‚  â”‚     â”‚  â”‚ InferenceEngine   â”‚  â”‚
â”‚  â”‚  â””â”€ vLLM/TensorRT â”‚  â”‚     â”‚  â”‚  â””â”€ MindIE/vLLM   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ TrainingEngine    â”‚  â”‚     â”‚  â”‚ TrainingEngine    â”‚  â”‚
â”‚  â”‚  â””â”€ LoRA/PEFT     â”‚  â”‚     â”‚  â”‚  â””â”€ LoRA/PEFT     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Redis        â”‚
                    â”‚   (ä»»åŠ¡é˜Ÿåˆ—+ç¼“å­˜)  â”‚
                    â”‚      :6379        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

è¯¦ç»†æ¶æ„è®¾è®¡è¯·å‚è€ƒ [docs/ARCHITECTURE.md](./docs/ARCHITECTURE.md)ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
CY-LLM-Engine/
â”œâ”€â”€ cy                           # ä¸» CLI å·¥å…· (Shell è„šæœ¬)
â”œâ”€â”€ cy-llm                       # CLI åˆ«å
â”œâ”€â”€ CY_LLM_Backend/
â”‚   â”œâ”€â”€ gateway/                # Kotlin Gateway æœåŠ¡ (Spring WebFlux)
â”‚   â”œâ”€â”€ coordinator/            # Kotlin Coordinator æœåŠ¡ (Spring Boot)
â”‚   â”œâ”€â”€ worker/                 # Python Worker æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ main.py             # å…¥å£ç‚¹
â”‚   â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒç»„ä»¶ (server, scheduler, memory, telemetry)
â”‚   â”‚   â”œâ”€â”€ engines/            # æ¨ç†å¼•æ“ (vLLM, TRT, MindIE, Ascend)
â”‚   â”‚   â”œâ”€â”€ training/           # è®­ç»ƒå¼•æ“ (LoRA/PEFT)
â”‚   â”‚   â”œâ”€â”€ config/             # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ cache/              # ç¼“å­˜æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ utils/              # å·¥å…·å‡½æ•°
â”‚   â”‚   â””â”€â”€ tests/              # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ deploy/                 # éƒ¨ç½²é…ç½® (docker-compose, config.json)
â”‚   â””â”€â”€ proto/                  # gRPC åè®®å®šä¹‰
â”œâ”€â”€ CY_LLM_Training/            # è®­ç»ƒç›¸å…³ä»£ç 
â”œâ”€â”€ scripts/                    # è¾…åŠ©è„šæœ¬
â”‚   â”œâ”€â”€ convert_trt.py          # TRT æ¨¡å‹è½¬æ¢å·¥å…·
â”‚   â””â”€â”€ diagnose_env.py         # ç¯å¢ƒè¯Šæ–­
â”œâ”€â”€ docs/                       # é¡¹ç›®æ–‡æ¡£
â”‚   â”œâ”€â”€ HISTORY/                # é¡¹ç›®å†å²æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md               # é¡¹ç›®è¯¦ç»†ä»‹ç»
â”‚   â”œâ”€â”€ INSTALL.md              # å®‰è£…æŒ‡å—
â”‚   â”œâ”€â”€ ARCHITECTURE.md         # æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ API.md                  # API æ–‡æ¡£
â”‚   â”œâ”€â”€ CONTRIBUTING.md         # è´¡çŒ®è§„èŒƒ
â”‚   â”œâ”€â”€ TESTING.md              # æµ‹è¯•æŒ‡å—
â”‚   â”œâ”€â”€ FAQ.md                  # å¸¸è§é—®é¢˜
â”‚   â””â”€â”€ TRT_GUIDE.md            # TRT ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ QUICK_START.md              # å¿«é€Ÿå¼€å§‹æŒ‡å—
â”œâ”€â”€ requirements*.txt           # Python ä¾èµ–
â””â”€â”€ LICENSE
```

---

## âš™ï¸ ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | æœ€ä½ç‰ˆæœ¬ | æ¨èç‰ˆæœ¬ |
|------|----------|----------|
| Python | 3.10+ | 3.11 |
| Java | 21+ | 21 (LTS) |
| CUDA | 12.0 | 12.4 |
| CANN | 8.0+ | 8.0.RC1 |
| Redis | 7.0 | 7.2 |
| Docker | 24.0 | 25.0 |

---

## ğŸ· ç‰ˆæœ¬å·è§„èŒƒ

æœ¬é¡¹ç›®é‡‡ç”¨ **å››æ®µå¼ç‰ˆæœ¬å·**: `[major.minor.patch.build-SUFFIX]`

| æ®µ | å«ä¹‰ | è¯´æ˜ |
|----|------|------|
| major | é‡å¤§ä¸å…¼å®¹å˜åŒ– | ç ´åæ€§é‡æ„ |
| minor | å‘åå…¼å®¹æ–°åŠŸèƒ½ | feature |
| patch | Bug ä¿®å¤ä¸ä¼˜åŒ– | bugfix |
| build | æ„å»º/æµ‹è¯•æ¬¡æ•° | é€’å¢ |
| SUFFIX | ç¨³å®šæ€§åç¼€ | PreAlpha/Alpha/Beta/RC/Release |

æäº¤æ¶ˆæ¯æ ¼å¼ï¼š
```
[2.1.1.2-Alpha] feat(worker): add async inference support

Add async inference support for vLLM engine.

ã€ä¸­æ–‡ã€‘workerï¼šæ·»åŠ å¼‚æ­¥æ¨ç†æ”¯æŒ
```

è¯¦ç»†è§„èŒƒè¯·å‚è€ƒ [docs/CONTRIBUTING.md](./docs/CONTRIBUTING.md)ã€‚

---

## ğŸ“ ç‰ˆæœ¬å†å²

- **[1.5.2.0]** - ç®€åŒ–éƒ¨ç½²æµç¨‹ï¼Œç»Ÿä¸€ CLI å·¥å…·ï¼Œæ”¯æŒå››ç§æ¨ç†å¼•æ“
- **[1.5.1.3-alpha]** - C++ å…¥å£ç‚¹ï¼Œå››å¼•æ“æ¶æ„å®ç°
- **[1.5.0.0-alpha]** - VRAM ä¼˜åŒ–ç³»ç»Ÿã€TRT çœŸæµå¼è¾“å‡º
- **[1.0.0-alpha]** - åˆå§‹ç‰ˆæœ¬ï¼ŒGateway + Worker åŸºç¡€æ¶æ„

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue æˆ– Pull Requestï¼

è¯¦ç»†è´¡çŒ®æŒ‡å—è¯·å‚è€ƒ [docs/CONTRIBUTING.md](./docs/CONTRIBUTING.md)ã€‚

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦è§ [LICENSE](./LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ”— ç›¸å…³é“¾æ¥

- **åœ¨çº¿æ–‡æ¡£**: [https://zread.ai/Baijin64/CY-LLM-Engine](https://zread.ai/Baijin64/CY-LLM-Engine)
- **é¡¹ç›®ä»“åº“**: [https://github.com/Baijin64/CY-LLM-Engine](https://github.com/Baijin64/CY-LLM-Engine)
- **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/Baijin64/CY-LLM-Engine/issues)
