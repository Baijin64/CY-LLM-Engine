# CY-LLM Engine Token Speed Baseline

## æ€§èƒ½åŸºçº¿è®°å½•

**è®°å½•æ—¥æœŸ**: 2026-02-10  
**è®°å½•ç‰ˆæœ¬**: v1.0  
**æµ‹è¯•ç¯å¢ƒ**: å¼€å‘ç¯å¢ƒ

---

## å½“å‰æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | çŠ¶æ€ |
|------|--------|--------|------|
| **Tokené€Ÿåº¦** | 15-20 tokens/s | â‰¥50 tokens/s | âŒ ä¸è¾¾æ ‡ |
| **TTFT (é¦–Tokenå»¶è¿Ÿ)** | ~500ms | â‰¤200ms | âŒ ä¸è¾¾æ ‡ |
| **å¹¶å‘å¤„ç†èƒ½åŠ›** | æœªæµ‹è¯• | æ”¯æŒ100å¹¶å‘ | â³ å¾…æµ‹è¯• |

### æ€§èƒ½å·®è·åˆ†æ

- Tokené€Ÿåº¦å·®è·: **2.5-3.3x** (ç›®æ ‡/å½“å‰)
- TTFTå·®è·: **2.5x** (ç›®æ ‡/å½“å‰)

---

## ç“¶é¢ˆåˆ†æ

### ğŸ”´ è‡´å‘½ç“¶é¢ˆ (P0)

#### 1. é€å­—ç¬¦yield (vllm_cuda_engine.py:500)
**ä½ç½®**: `CY_LLM_Backend/worker/engines/vllm_cuda_engine.py` ç¬¬495-501è¡Œ

```python
# å½“å‰ä»£ç ï¼ˆé—®é¢˜ï¼‰
outputs = self._llm.generate([prompt], **request_kwargs)
if outputs and len(outputs) > 0:
    generated_text = outputs[0].outputs[0].text
    for char in generated_text:  # <-- è‡´å‘½é—®é¢˜
        yield char
```

**é—®é¢˜**:
1. vLLMå…ˆç”Ÿæˆå®Œæ•´æ–‡æœ¬ï¼ˆé˜»å¡ï¼‰
2. ç„¶åé€å­—ç¬¦yieldï¼Œæ¯æ¬¡yieldäº§ç”Ÿå·¨å¤§å¼€é”€
3. æ¯æ¬¡å­—ç¬¦yieldéƒ½ç»è¿‡å®Œæ•´çš„Pythonç”Ÿæˆå™¨åè®®

**é¢„æœŸä¼˜åŒ–æ”¶ç›Š**: 15â†’35+ tokens/s (å•æ­¤ä¼˜åŒ–)

### ğŸŸ¡ æ¶æ„ç“¶é¢ˆ (P1)

#### 2. åŒæ­¥å¼•æ“ä½¿ç”¨
**ä½ç½®**: `CY_LLM_Backend/worker/engines/engine_factory.py` é»˜è®¤é…ç½®

- å½“å‰é»˜è®¤å¼•æ“: `cuda-vllm` (åŒæ­¥LLM)
- å¯ç”¨å¼‚æ­¥å¼•æ“: `cuda-vllm-async` (AsyncLLMEngine)

**é—®é¢˜**:
- åŒæ­¥å¼•æ“éœ€è¦ç­‰å¾…å®Œæ•´ç”Ÿæˆ
- TTFTæ— æ³•ä¼˜åŒ–åˆ°<200ms

**é¢„æœŸä¼˜åŒ–æ”¶ç›Š**: TTFT 500msâ†’50ms, Tokené€Ÿåº¦ 35â†’50+ tokens/s

#### 3. gRPCæ¶ˆæ¯ä¼ è¾“ç²’åº¦
**ä½ç½®**: `CY_LLM_Backend/worker/grpc_servicer.py:231-237`

- æ¯ä¸ªyieldäº§ç”Ÿä¸€ä¸ªgRPCå“åº”
- é€å­—ç¬¦å¯¼è‡´å¤§é‡ç½‘ç»œå¾€è¿”

**é¢„æœŸä¼˜åŒ–æ”¶ç›Š**: å‡å°‘ç½‘ç»œå¼€é”€20-30%

---

## æµ‹è¯•ç¯å¢ƒä¿¡æ¯

### ç¡¬ä»¶é…ç½®
| é¡¹ç›® | å€¼ |
|------|-----|
| GPUå‹å· | å¾…æµ‹è¯•ç¯å¢ƒç¡®å®š |
| GPUæ˜¾å­˜ | å¾…æµ‹è¯•ç¯å¢ƒç¡®å®š |
| CUDAç‰ˆæœ¬ | å¾…æµ‹è¯•ç¯å¢ƒç¡®å®š |

### è½¯ä»¶é…ç½®
| é¡¹ç›® | å½“å‰å€¼ |
|------|--------|
| Pythonç‰ˆæœ¬ | 3.12.12 |
| vLLMç‰ˆæœ¬ | å¾…å®‰è£… |
| PyTorchç‰ˆæœ¬ | å¾…éªŒè¯ |
| gRPCç‰ˆæœ¬ | å¾…éªŒè¯ |

---

## æµ‹è¯•å‘½ä»¤

### 1. è¿è¡ŒåŸºå‡†æµ‹è¯•
```bash
# æµ‹è¯•å½“å‰å¼•æ“ï¼ˆåŒæ­¥vLLMï¼‰
python scripts/benchmark_token_speed.py \
    --model deepseek-ai/deepseek-llm-7b-chat \
    --engine cuda-vllm \
    --output docs/refactor/token-speed-optimization/baseline_result.json

# æµ‹è¯•å¼‚æ­¥å¼•æ“ï¼ˆä¼˜åŒ–åï¼‰
python scripts/benchmark_token_speed.py \
    --model deepseek-ai/deepseek-llm-7b-chat \
    --engine cuda-vllm-async \
    --output docs/refactor/token-speed-optimization/optimized_result.json

# å¤šè½®æµ‹è¯•å–å¹³å‡
python scripts/benchmark_token_speed.py \
    --model deepseek-ai/deepseek-llm-7b-chat \
    --engine cuda-vllm \
    --runs 5 \
    --output docs/refactor/token-speed-optimization/baseline_avg.json
```

### 2. å¯¹æ¯”æµ‹è¯•
```bash
# å¯¹æ¯”ä¼˜åŒ–å‰å
python scripts/benchmark_compare.py \
    --before docs/refactor/token-speed-optimization/baseline_result.json \
    --after docs/refactor/token-speed-optimization/optimized_result.json
```

---

## æ„å»ºå‘½ä»¤

### å®‰è£…ä¾èµ–
```bash
# åŸºç¡€ä¾èµ–
pip install -e .

# vLLMå¼•æ“
pip install vllm==0.12.0

# æµ‹è¯•ä¾èµ–
pip install pytest pytest-benchmark pytest-asyncio
```

### éªŒè¯å®‰è£…
```bash
# éªŒè¯å¼•æ“å¯ç”¨
python -c "from worker.engines import check_engine_available; print(check_engine_available('cuda-vllm'))"
python -c "from worker.engines import check_engine_available; print(check_engine_available('cuda-vllm-async'))"

# éªŒè¯é»˜è®¤å¼•æ“
python -c "from worker.engines.engine_factory import EngineFactory; print(EngineFactory.auto_detect())"
```

---

## å›å½’æµ‹è¯•å‘½ä»¤

```bash
# å•å…ƒæµ‹è¯•
pytest tests/unit/test_vllm_cuda_engine_streaming.py -v

# é›†æˆæµ‹è¯•
pytest tests/integration/test_streaming_performance.py -v --timeout=300

# æ€§èƒ½æµ‹è¯•
pytest tests/performance/ -m performance --benchmark-only

# å…¨é‡å›å½’
pytest tests/ -xvs -k "not slow"
```

---

## æµ‹è¯•æ•°æ®é›†

### æ ‡å‡†æµ‹è¯•Prompts

#### Prompt 1: ä¸­æ–‡é•¿æ–‡æœ¬ç”Ÿæˆ
```
è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼ŒåŒ…æ‹¬å…¶å†å²ã€ç°çŠ¶å’Œæœªæ¥å‘å±•è¶‹åŠ¿ã€‚
è¦æ±‚ï¼š
1. ä»å†å²è§’åº¦å›é¡¾AIçš„å‘å±•
2. åˆ†æå½“å‰AIæŠ€æœ¯çš„æ ¸å¿ƒèƒ½åŠ›
3. é¢„æµ‹æœªæ¥10å¹´çš„å‘å±•æ–¹å‘
4. è®¨è®ºå¯èƒ½é¢ä¸´çš„æŒ‘æˆ˜å’Œä¼¦ç†é—®é¢˜
```

#### Prompt 2: ä»£ç ç”Ÿæˆ
```
è¯·ç”¨Pythonå®ç°ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ï¼Œå¹¶æ·»åŠ è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šã€‚
è¦æ±‚ï¼š
1. å®ç°å®Œæ•´çš„quicksortå‡½æ•°
2. åŒ…å«partitionè¾…åŠ©å‡½æ•°
3. æ·»åŠ æ—¶é—´å¤æ‚åº¦åˆ†æ
4. æä¾›æµ‹è¯•ç”¨ä¾‹
```

#### Prompt 3: æ•°å­¦æ¨ç†
```
è¯·é€æ­¥æ¨å¯¼æ±‚è§£ä»¥ä¸‹æ–¹ç¨‹ï¼š
2x^2 + 5x - 3 = 0

è¦æ±‚ï¼š
1. ä½¿ç”¨æ±‚æ ¹å…¬å¼
2. å±•ç¤ºå®Œæ•´æ¨å¯¼è¿‡ç¨‹
3. éªŒè¯ç»“æœæ­£ç¡®æ€§
```

---

## åŸºçº¿æµ‹è¯•è®°å½•

### æµ‹è¯•è®°å½•æ¨¡æ¿

| æ—¥æœŸ | å¼•æ“ | æ¨¡å‹ | Tokené€Ÿåº¦ | TTFT | æµ‹è¯•äºº | å¤‡æ³¨ |
|------|------|------|-----------|------|--------|------|
| 2026-02-10 | cuda-vllm | deepseek-7b | 15-20 t/s | ~500ms | - | ä¼˜åŒ–å‰åŸºçº¿ |
| | | | | | | |

---

## ä¼˜åŒ–é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | ç›®æ ‡Tokené€Ÿåº¦ | ç›®æ ‡TTFT | éªŒæ”¶æ ‡å‡† |
|--------|---------------|----------|----------|
| M1: æµå¼ä¼˜åŒ–å®Œæˆ | â‰¥35 t/s | <600ms | TASK-001å®Œæˆ |
| M2: gRPCä¼˜åŒ–å®Œæˆ | â‰¥40 t/s | <500ms | TASK-002å®Œæˆ |
| M3: é»˜è®¤å¼•æ“åˆ‡æ¢ | â‰¥50 t/s | â‰¤200ms | TASK-003å®Œæˆ |

---

## é™„å½•

### æœ¯è¯­è¡¨
| æœ¯è¯­ | è¯´æ˜ |
|------|------|
| TTFT | Time To First Tokenï¼Œé¦–tokenå»¶è¿Ÿ |
| TPS | Tokens Per Secondï¼Œæ¯ç§’ç”Ÿæˆtokenæ•° |
| yield | Pythonç”Ÿæˆå™¨å…³é”®å­— |
| AsyncLLMEngine | vLLMå¼‚æ­¥æ¨ç†å¼•æ“ |

### å‚è€ƒé“¾æ¥
- [vLLMæ€§èƒ½ä¼˜åŒ–æŒ‡å—](https://docs.vllm.ai/en/latest/getting_started/performance.html)
- [gRPC Pythonæ€§èƒ½](https://grpc.io/docs/guides/performance/)

---

*æ–‡æ¡£ç‰ˆæœ¬: v1.0*  
*æœ€åæ›´æ–°: 2026-02-10*  
*ç»´æŠ¤è€…: CY-LLM Engine Team*
