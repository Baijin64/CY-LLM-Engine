# Token Speed Optimization - Refactor Goals

## 重构目标 (Goals)

### G1: 消除逐字符yield瓶颈
**当前问题**: `vllm_cuda_engine.py:500` 将完整输出逐字符yield
**解决方案**: 
- 方式A: 按token或合理块大小yield (最少改动)
- 方式B: 切换到AsyncLLMEngine真正流式 (最佳性能)

**预期收益**: Token速度 15→50 tokens/s

### G2: 优化gRPC消息传输
**当前问题**: 每个yield产生一个gRPC消息
**解决方案**: 
- 引入缓冲批处理，每N个tokens或每T毫秒批量发送
- 设置合理的flush间隔

**预期收益**: 减少网络往返开销

### G3: 使用AsyncLLMEngine（可选增强）
**当前问题**: 使用同步LLM.generate()阻塞式生成
**解决方案**:
- 将 `cuda-vllm-async` 设为默认引擎
- 保持 `cuda-vllm` 作为兼容选项

**预期收益**: TTFT从500ms降至50ms

## 非目标 (Non-Goals)

### NG1: 不修改外部API
- OpenAI兼容API响应格式不变
- gRPC消息结构不变
- 环境变量配置不变

### NG2: 不引入新依赖
- 仅使用现有vLLM功能
- 不添加新的pip包依赖

### NG3: 不修改模型层
- 模型加载流程不变
- 量化配置不变
- LoRA支持不变

## 验收标准

### 性能指标
| 指标 | 当前值 | 目标值 | 测量方法 |
|------|--------|--------|----------|
| Token速度 | 15-20 t/s | ≥50 t/s | benchmark脚本 |
| TTFT | ~500ms | ≤200ms | 日志时间戳 |
| 并发延迟 | 高 | 低 | 多客户端测试 |

### 质量指标
| 指标 | 当前值 | 目标值 | 验证方法 |
|------|--------|--------|----------|
| 单元测试通过率 | ? | 100% | pytest |
| API兼容性 | - | 100% | 回归测试 |
| 功能完整性 | - | 无缺失 | 人工验证 |

## 风险评估

### 高风险
- **R1**: AsyncLLMEngine与现有同步接口不兼容
- **R2**: 批处理引入延迟感知问题

### 中风险
- **R3**: 性能优化引入并发bug

### 缓解措施
- 保留原引擎作为fallback
- 添加全面的回归测试
- 渐进式发布（灰度）
