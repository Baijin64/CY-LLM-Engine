# å¿«é€Ÿå¼€å§‹æŒ‡ä»¤é€ŸæŸ¥

## ğŸš€ åŸºç¡€å¯åŠ¨

```bash
# åˆå§‹åŒ–ç¯å¢ƒ
./cy-llm setup --engine cuda-vllm

# å¯åŠ¨æœåŠ¡
./cy-llm lite --engine cuda-vllm --model qwen2.5-7b

# æµ‹è¯•
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"qwen2.5-7b","messages":[{"role":"user","content":"ä½ å¥½"}]}'
```

## ğŸ³ Docker å¯åŠ¨

```bash
# å¯åŠ¨
docker compose -f docker-compose.community.yml up -d

# æŸ¥çœ‹çŠ¶æ€
docker compose -f docker-compose.community.yml ps

# åœæ­¢
docker compose -f docker-compose.community.yml down
```

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

```bash
# ç¯å¢ƒè¯Šæ–­
./cy-llm doctor

# æ¨¡å‹æ˜¾å­˜è¯Šæ–­
./cy-llm diagnose qwen2.5-7b

# éªŒè¯é…ç½®æ–‡ä»¶
./cy-llm config validate

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
./cy-llm status

# åœæ­¢æœåŠ¡
./cy-llm stop

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
./cy-llm models list
```

## âš¡ TensorRT-LLM åŠ é€Ÿ

```bash
# è½¬æ¢æ¨¡å‹
./cy-llm convert-trt \
  --model Qwen/Qwen2.5-7B-Instruct \
  --output /models/qwen2.5-7b-trt

# ä½¿ç”¨ TRT å¼•æ“å¯åŠ¨
./cy-llm lite --engine cuda-trt --model qwen2.5-7b-trt
```

## ğŸ“ è®­ç»ƒç›¸å…³

```bash
# æ•°æ®é¢„å¤„ç†
./cy-llm prepare --raw ./raw_data --out ./data/train.jsonl --char èŠ™å®å¨œ

# å¯åŠ¨è®­ç»ƒ
./cy-llm train \
  --dataset ./data/train.jsonl \
  --output ./checkpoints/lora_v1 \
  --model facebook/opt-2.7b

# äº¤äº’å¼æµ‹è¯•
./cy-llm chat --model facebook/opt-2.7b --lora ./checkpoints/lora_v1
```

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œé›†æˆæµ‹è¯•
./cy-llm test integration

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
./cy-llm test all
```

## ğŸ“š æ›´å¤šä¿¡æ¯

è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒï¼š
- [README.md](./README.md) - å®Œæ•´é¡¹ç›®ä»‹ç»
- [docs/INSTALL.md](./docs/INSTALL.md) - è¯¦ç»†å®‰è£…æŒ‡å—
- [docs/TRT_GUIDE.md](./docs/TRT_GUIDE.md) - TensorRT-LLM å®Œæ•´æŒ‡å—
- [docs/FAQ.md](./docs/FAQ.md) - å¸¸è§é—®é¢˜è§£ç­”
